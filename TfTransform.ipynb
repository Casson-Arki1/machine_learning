{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c65927af",
   "metadata": {},
   "source": [
    "# Lab: TfTransform # \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Learning Objectives**\n",
    "1. Preprocess data and engineer new features using TfTransform \n",
    "1. Create and deploy Apache Beam pipeline \n",
    "1. Use processed data to train taxifare model locally then serve a prediction\n",
    "\n",
    "## Introduction \n",
    "While Pandas is fine for experimenting, for operationalization of your workflow it is better to do preprocessing in Apache Beam. This will also help if you need to preprocess data in flight, since Apache Beam allows for streaming. In this lab we will pull data from BigQuery then use Apache Beam  TfTransform to process the data.  \n",
    "\n",
    "Only specific combinations of TensorFlow/Beam are supported by tf.transform so make sure to get a combo that works. In this lab we will be using: \n",
    "* TFT 0.24.0\n",
    "* TF 2.3.0 \n",
    "* Apache Beam [GCP] 2.24.0\n",
    "\n",
    "Each learning objective will correspond to a __#TODO__ in the [student lab notebook](https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive2/feature_engineering/labs/5_tftransform_taxifare.ipynb) -- try to complete that notebook first before reviewing this solution notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63551f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the chown command to change the ownership\n",
    "!sudo chown -R jupyter:jupyter /home/jupyter/machine_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77442e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.3.0\n",
      "  Downloading tensorflow-2.3.0-cp37-cp37m-manylinux2010_x86_64.whl (320.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 320.4 MB 33 kB/s s eta 0:00:011\n",
      "\u001b[?25hCollecting apache-beam[gcp]==2.24.0\n",
      "  Downloading apache_beam-2.24.0-cp37-cp37m-manylinux2010_x86_64.whl (8.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.5 MB 25.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.0) (1.16.0)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting keras-preprocessing<1.2,>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 1.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.0) (1.38.1)\n",
      "Collecting absl-py>=0.7.0\n",
      "  Downloading absl_py-0.13.0-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 58.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.8\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 7.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.0) (0.36.2)\n",
      "Collecting numpy<1.19.0,>=1.16.0\n",
      "  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.1 MB 67.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse==1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting h5py<2.11.0,>=2.10.0\n",
      "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 53.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.0) (3.16.0)\n",
      "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
      "  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
      "\u001b[K     |████████████████████████████████| 459 kB 68.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.0) (1.12.1)\n",
      "Collecting scipy==1.4.1\n",
      "  Downloading scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.1 MB 54.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 5.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<3,>=2.3.0\n",
      "  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.0 MB 59.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydot<2,>=1.2.0\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Collecting pyarrow<0.18.0,>=0.15.1\n",
      "  Downloading pyarrow-0.17.1-cp37-cp37m-manylinux2014_x86_64.whl (63.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 63.8 MB 167 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2018.3 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]==2.24.0) (2021.1)\n",
      "Collecting typing-extensions<3.8.0,>=3.7.0\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting pymongo<4.0.0,>=3.8.0\n",
      "  Downloading pymongo-3.12.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (526 kB)\n",
      "\u001b[K     |████████████████████████████████| 526 kB 51.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fastavro<0.24,>=0.21.4\n",
      "  Downloading fastavro-0.23.6-cp37-cp37m-manylinux2010_x86_64.whl (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 45.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3,>=2.8.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]==2.24.0) (2.8.1)\n",
      "Requirement already satisfied: future<1.0.0,>=0.18.2 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]==2.24.0) (0.18.2)\n",
      "Collecting crcmod<2.0,>=1.7\n",
      "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
      "\u001b[K     |████████████████████████████████| 89 kB 12.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting oauth2client<4,>=2.0.1\n",
      "  Downloading oauth2client-3.0.0.tar.gz (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 7.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
      "  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n",
      "Collecting avro-python3!=1.9.2,<1.10.0,>=1.8.1\n",
      "  Downloading avro-python3-1.9.2.1.tar.gz (37 kB)\n",
      "Collecting httplib2<0.18.0,>=0.8\n",
      "  Downloading httplib2-0.17.4-py3-none-any.whl (95 kB)\n",
      "\u001b[K     |████████████████████████████████| 95 kB 5.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]==2.24.0) (2.25.1)\n",
      "Collecting mock<3.0.0,>=1.0.1\n",
      "  Downloading mock-2.0.0-py2.py3-none-any.whl (56 kB)\n",
      "\u001b[K     |████████████████████████████████| 56 kB 7.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 63.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-spanner<2,>=1.13.0\n",
      "  Downloading google_cloud_spanner-1.19.1-py2.py3-none-any.whl (255 kB)\n",
      "\u001b[K     |████████████████████████████████| 255 kB 40.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-language<2,>=1.3.0\n",
      "  Downloading google_cloud_language-1.3.0-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[K     |████████████████████████████████| 83 kB 3.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: grpcio-gcp<1,>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]==2.24.0) (0.2.2)\n",
      "Requirement already satisfied: google-cloud-pubsub<2,>=0.39.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]==2.24.0) (1.7.0)\n",
      "Collecting google-cloud-datastore<2,>=1.7.1\n",
      "  Downloading google_cloud_datastore-1.15.3-py2.py3-none-any.whl (134 kB)\n",
      "\u001b[K     |████████████████████████████████| 134 kB 82.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-apitools<0.5.32,>=0.5.31\n",
      "  Downloading google-apitools-0.5.31.tar.gz (173 kB)\n",
      "\u001b[K     |████████████████████████████████| 173 kB 49.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-bigquery<2,>=1.6.0\n",
      "  Downloading google_cloud_bigquery-1.28.0-py2.py3-none-any.whl (187 kB)\n",
      "\u001b[K     |████████████████████████████████| 187 kB 59.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<4,>=3.1.0\n",
      "  Downloading cachetools-3.1.1-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: google-auth<2,>=1.18.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]==2.24.0) (1.32.1)\n",
      "Collecting google-cloud-bigtable<2,>=0.31.1\n",
      "  Downloading google_cloud_bigtable-1.7.0-py2.py3-none-any.whl (267 kB)\n",
      "\u001b[K     |████████████████████████████████| 267 kB 66.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-videointelligence<2,>=1.8.0\n",
      "  Downloading google_cloud_videointelligence-1.16.1-py2.py3-none-any.whl (183 kB)\n",
      "\u001b[K     |████████████████████████████████| 183 kB 81.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-vision<2,>=0.38.0\n",
      "  Downloading google_cloud_vision-1.0.0-py2.py3-none-any.whl (435 kB)\n",
      "\u001b[K     |████████████████████████████████| 435 kB 44.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-dlp<2,>=0.12.0\n",
      "  Downloading google_cloud_dlp-1.0.0-py2.py3-none-any.whl (169 kB)\n",
      "\u001b[K     |████████████████████████████████| 169 kB 57.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-cloud-core<2,>=0.28.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]==2.24.0) (1.7.1)\n",
      "Collecting fasteners>=0.14\n",
      "  Downloading fasteners-0.16.3-py2.py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.18.0->apache-beam[gcp]==2.24.0) (4.7.2)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.18.0->apache-beam[gcp]==2.24.0) (49.6.0.post20210108)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.18.0->apache-beam[gcp]==2.24.0) (0.2.7)\n",
      "Requirement already satisfied: google-api-core<2.0dev,>=1.21.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<2,>=1.6.0->apache-beam[gcp]==2.24.0) (1.30.0)\n",
      "Requirement already satisfied: google-resumable-media<2.0dev,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<2,>=1.6.0->apache-beam[gcp]==2.24.0) (1.3.1)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.21.0->google-cloud-bigquery<2,>=1.6.0->apache-beam[gcp]==2.24.0) (21.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.21.0->google-cloud-bigquery<2,>=1.6.0->apache-beam[gcp]==2.24.0) (1.53.0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<0.13dev,>=0.12.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigtable<2,>=0.31.1->apache-beam[gcp]==2.24.0) (0.12.3)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery<2,>=1.6.0->apache-beam[gcp]==2.24.0) (1.1.2)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery<2,>=1.6.0->apache-beam[gcp]==2.24.0) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery<2,>=1.6.0->apache-beam[gcp]==2.24.0) (2.20)\n",
      "Collecting docopt\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "Collecting pbr>=0.11\n",
      "  Downloading pbr-5.6.0-py2.py3-none-any.whl (111 kB)\n",
      "\u001b[K     |████████████████████████████████| 111 kB 76.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.7/site-packages (from oauth2client<4,>=2.0.1->apache-beam[gcp]==2.24.0) (0.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->google-api-core<2.0dev,>=1.21.0->google-cloud-bigquery<2,>=1.6.0->apache-beam[gcp]==2.24.0) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]==2.24.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]==2.24.0) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]==2.24.0) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]==2.24.0) (4.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.4)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 64.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-2.0.1-py3-none-any.whl (288 kB)\n",
      "\u001b[K     |████████████████████████████████| 288 kB 57.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 46.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.10.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.5.0)\n",
      "Building wheels for collected packages: avro-python3, crcmod, dill, google-apitools, oauth2client, termcolor, docopt\n",
      "  Building wheel for avro-python3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for avro-python3: filename=avro_python3-1.9.2.1-py3-none-any.whl size=43512 sha256=196e838d74253aa3770b4bb908bc08a65d036a552eeee8b509312d65f65e88de\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/bc/49/5f/fdb5b9d85055c478213e0158ac122b596816149a02d82e0ab1\n",
      "  Building wheel for crcmod (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for crcmod: filename=crcmod-1.7-cp37-cp37m-linux_x86_64.whl size=36810 sha256=57ef6a991f5f2d640d9596c491094dcd5031260aad695e3990389a303989b00e\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/dc/9a/e9/49e627353476cec8484343c4ab656f1e0d783ee77b9dde2d1f\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78532 sha256=75edd40e96eec2cf9f1b524ace582e8b26326a04da83a7abaf24b44089480eac\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
      "  Building wheel for google-apitools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for google-apitools: filename=google_apitools-0.5.31-py3-none-any.whl size=131041 sha256=0a0d24a4b40507a99b0d2d84cf2db6fb3f6820bcaf3883f2565930df391b9516\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/19/b5/2f/1cc3cf2b31e7a9cd1508731212526d9550271274d351c96f16\n",
      "  Building wheel for oauth2client (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for oauth2client: filename=oauth2client-3.0.0-py3-none-any.whl size=106381 sha256=9224a3a7605a1ee9677e2f262dd97a71d8c9df574767fcb50d090fcc90225d54\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/86/73/7a/3b3f76a2142176605ff38fbca574327962c71e25a43197a4c1\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=660f03ba5e9d33e44cf96ad5e70779670378236d595f6c474fa276f5433d0d36\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=ab7aace5288a91c5f47a18e3f4037ba7bfbd7e776de22992e2d478df2b1277ee\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
      "Successfully built avro-python3 crcmod dill google-apitools oauth2client termcolor docopt\n",
      "Installing collected packages: cachetools, typing-extensions, pbr, numpy, httplib2, docopt, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, pymongo, pydot, pyarrow, oauth2client, mock, hdfs, fasteners, fastavro, dill, crcmod, avro-python3, absl-py, termcolor, tensorflow-estimator, tensorboard, scipy, opt-einsum, keras-preprocessing, h5py, google-pasta, google-cloud-vision, google-cloud-videointelligence, google-cloud-spanner, google-cloud-language, google-cloud-dlp, google-cloud-datastore, google-cloud-bigtable, google-cloud-bigquery, google-apitools, gast, astunparse, apache-beam, tensorflow\n",
      "  Attempting uninstall: cachetools\n",
      "    Found existing installation: cachetools 4.2.2\n",
      "    Uninstalling cachetools-4.2.2:\n",
      "      Successfully uninstalled cachetools-4.2.2\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.0\n",
      "    Uninstalling typing-extensions-3.10.0.0:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Attempting uninstall: httplib2\n",
      "    Found existing installation: httplib2 0.19.1\n",
      "    Uninstalling httplib2-0.19.1:\n",
      "      Successfully uninstalled httplib2-0.19.1\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 4.0.1\n",
      "    Uninstalling pyarrow-4.0.1:\n",
      "      Successfully uninstalled pyarrow-4.0.1\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.7.0\n",
      "    Uninstalling scipy-1.7.0:\n",
      "      Successfully uninstalled scipy-1.7.0\n",
      "  Attempting uninstall: google-cloud-vision\n",
      "    Found existing installation: google-cloud-vision 2.4.0\n",
      "    Uninstalling google-cloud-vision-2.4.0:\n",
      "      Successfully uninstalled google-cloud-vision-2.4.0\n",
      "  Attempting uninstall: google-cloud-videointelligence\n",
      "    Found existing installation: google-cloud-videointelligence 2.3.0\n",
      "    Uninstalling google-cloud-videointelligence-2.3.0:\n",
      "      Successfully uninstalled google-cloud-videointelligence-2.3.0\n",
      "  Attempting uninstall: google-cloud-spanner\n",
      "    Found existing installation: google-cloud-spanner 3.6.0\n",
      "    Uninstalling google-cloud-spanner-3.6.0:\n",
      "      Successfully uninstalled google-cloud-spanner-3.6.0\n",
      "  Attempting uninstall: google-cloud-language\n",
      "    Found existing installation: google-cloud-language 2.2.0\n",
      "    Uninstalling google-cloud-language-2.2.0:\n",
      "      Successfully uninstalled google-cloud-language-2.2.0\n",
      "  Attempting uninstall: google-cloud-datastore\n",
      "    Found existing installation: google-cloud-datastore 2.1.4\n",
      "    Uninstalling google-cloud-datastore-2.1.4:\n",
      "      Successfully uninstalled google-cloud-datastore-2.1.4\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 13] Permission denied: 'helpers.cpython-37.pyc'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Collecting tensorflow-transform==0.24.0\n",
      "  Downloading tensorflow_transform-0.24.0-py3-none-any.whl (373 kB)\n",
      "\u001b[K     |████████████████████████████████| 373 kB 8.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-transform==0.24.0) (3.16.0)\n",
      "Requirement already satisfied: pydot<2,>=1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-transform==0.24.0) (1.4.2)\n",
      "Requirement already satisfied: six<2,>=1.12 in /opt/conda/lib/python3.7/site-packages (from tensorflow-transform==0.24.0) (1.16.0)\n",
      "Requirement already satisfied: numpy<2,>=1.16 in /opt/conda/lib/python3.7/site-packages (from tensorflow-transform==0.24.0) (1.18.5)\n",
      "Collecting absl-py<0.11,>=0.9\n",
      "  Downloading absl_py-0.10.0-py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 14.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tfx-bsl<0.25,>=0.24\n",
      "  Downloading tfx_bsl-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 18.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<2.4,>=1.15.2\n",
      "  Downloading tensorflow-2.3.3-cp37-cp37m-manylinux2010_x86_64.whl (320.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 320.5 MB 10 kB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting apache-beam[gcp]<3,>=2.23\n",
      "  Downloading apache_beam-2.31.0-cp37-cp37m-manylinux2010_x86_64.whl (9.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.7 MB 58.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-metadata<0.25,>=0.24\n",
      "  Downloading tensorflow_metadata-0.24.0-py3-none-any.whl (44 kB)\n",
      "\u001b[K     |████████████████████████████████| 44 kB 3.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3,>=2.8.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (2.8.1)\n",
      "Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (3.7.4.3)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (2.6.0)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (0.3.1.1)\n",
      "Requirement already satisfied: pytz>=2018.3 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (2021.1)\n",
      "Requirement already satisfied: avro-python3!=1.9.2,<1.10.0,>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (1.9.2.1)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (3.12.0)\n",
      "Requirement already satisfied: future<1.0.0,>=0.18.2 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (0.18.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (2.25.1)\n",
      "Requirement already satisfied: fastavro<2,>=0.21.4 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (0.23.6)\n",
      "Requirement already satisfied: httplib2<0.20.0,>=0.8 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (0.17.4)\n",
      "Requirement already satisfied: grpcio<2,>=1.29.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (1.38.1)\n",
      "Requirement already satisfied: oauth2client<5,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (3.0.0)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (1.7)\n",
      "Requirement already satisfied: pyarrow<5.0.0,>=0.15.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (0.17.1)\n",
      "Collecting google-cloud-profiler<4,>=3.0.4\n",
      "  Downloading google-cloud-profiler-3.0.5.tar.gz (34 kB)\n",
      "Requirement already satisfied: google-cloud-videointelligence<2,>=1.8.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (1.16.1)\n",
      "Requirement already satisfied: google-cloud-datastore<2,>=1.7.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (1.15.3)\n",
      "Requirement already satisfied: google-cloud-core<2,>=0.28.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (1.7.1)\n",
      "Requirement already satisfied: google-cloud-language<2,>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (1.3.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.18.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (1.32.1)\n",
      "Requirement already satisfied: google-cloud-pubsub<2,>=0.39.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (1.7.0)\n",
      "Requirement already satisfied: google-cloud-vision<2,>=0.38.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (1.0.0)\n",
      "Requirement already satisfied: google-cloud-bigquery<3,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (2.20.0)\n",
      "Collecting google-cloud-bigtable<2,>=0.31.1\n",
      "  Using cached google_cloud_bigtable-1.7.0-py2.py3-none-any.whl (267 kB)\n",
      "Requirement already satisfied: google-cloud-dlp<2,>=0.12.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (1.0.0)\n",
      "Collecting google-apitools<0.5.32,>=0.5.31\n",
      "  Using cached google_apitools-0.5.31-py3-none-any.whl\n",
      "Requirement already satisfied: cachetools<5,>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (3.1.1)\n",
      "Requirement already satisfied: grpcio-gcp<1,>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (0.2.2)\n",
      "Requirement already satisfied: google-cloud-spanner<2,>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (1.19.1)\n",
      "Requirement already satisfied: fasteners>=0.14 in /opt/conda/lib/python3.7/site-packages (from google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (0.16.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.18.0->apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.18.0->apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (0.2.7)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.18.0->apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (49.6.0.post20210108)\n",
      "Requirement already satisfied: google-resumable-media<2.0dev,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3,>=1.6.0->apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (1.3.1)\n",
      "Requirement already satisfied: proto-plus>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3,>=1.6.0->apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (1.19.0)\n",
      "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.29.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3,>=1.6.0->apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (1.30.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3,>=1.6.0->apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (21.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.29.0->google-cloud-bigquery<3,>=1.6.0->apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (1.53.0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<0.13dev,>=0.12.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigtable<2,>=0.31.1->apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (0.12.3)\n",
      "Requirement already satisfied: google-api-python-client!=1.12.0,!=2.0.2 in /opt/conda/lib/python3.7/site-packages (from google-cloud-profiler<4,>=3.0.4->apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (2.12.0)\n",
      "Requirement already satisfied: google-auth-httplib2 in /opt/conda/lib/python3.7/site-packages (from google-cloud-profiler<4,>=3.0.4->apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (0.1.0)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client!=1.12.0,!=2.0.2->google-cloud-profiler<4,>=3.0.4->apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (3.0.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery<3,>=1.6.0->apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (1.1.2)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery<3,>=1.6.0->apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery<3,>=1.6.0->apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (2.20)\n",
      "Requirement already satisfied: docopt in /opt/conda/lib/python3.7/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (0.6.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.7/site-packages (from oauth2client<5,>=2.0.1->apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (0.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->google-cloud-bigquery<3,>=1.6.0->apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.23->tensorflow-transform==0.24.0) (4.0.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<2.4,>=1.15.2->tensorflow-transform==0.24.0) (2.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<2.4,>=1.15.2->tensorflow-transform==0.24.0) (1.12.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<2.4,>=1.15.2->tensorflow-transform==0.24.0) (3.3.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<2.4,>=1.15.2->tensorflow-transform==0.24.0) (2.10.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<2.4,>=1.15.2->tensorflow-transform==0.24.0) (0.2.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<2.4,>=1.15.2->tensorflow-transform==0.24.0) (0.36.2)\n",
      "Collecting gast==0.3.3\n",
      "  Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<2.4,>=1.15.2->tensorflow-transform==0.24.0) (1.1.2)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<2.4,>=1.15.2->tensorflow-transform==0.24.0) (2.5.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<2.4,>=1.15.2->tensorflow-transform==0.24.0) (1.1.0)\n",
      "Collecting astunparse==1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<2.4,>=1.15.2->tensorflow-transform==0.24.0) (2.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<2.4,>=1.15.2->tensorflow-transform==0.24.0) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<2.4,>=1.15.2->tensorflow-transform==0.24.0) (0.4.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<2.4,>=1.15.2->tensorflow-transform==0.24.0) (1.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<2.4,>=1.15.2->tensorflow-transform==0.24.0) (3.3.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<2.4,>=1.15.2->tensorflow-transform==0.24.0) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<2.4,>=1.15.2->tensorflow-transform==0.24.0) (3.10.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<2.4,>=1.15.2->tensorflow-transform==0.24.0) (3.1.1)\n",
      "Requirement already satisfied: pandas<2,>=1.0 in /opt/conda/lib/python3.7/site-packages (from tfx-bsl<0.25,>=0.24->tensorflow-transform==0.24.0) (1.3.0)\n",
      "Collecting tensorflow-serving-api!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15\n",
      "  Downloading tensorflow_serving_api-2.5.1-py2.py3-none-any.whl (38 kB)\n",
      "Collecting google-api-python-client!=1.12.0,!=2.0.2\n",
      "  Downloading google_api_python_client-1.12.8-py2.py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 40 kB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-serving-api!=2.0.*,!=2.1.*,!=2.2.*,<3,>=1.15\n",
      "  Downloading tensorflow_serving_api-2.4.2-py2.py3-none-any.whl (38 kB)\n",
      "  Downloading tensorflow_serving_api-2.4.1-py2.py3-none-any.whl (38 kB)\n",
      "  Downloading tensorflow_serving_api-2.4.0-py2.py3-none-any.whl (38 kB)\n",
      "  Downloading tensorflow_serving_api-2.3.0-py2.py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,<2.4,>=1.15.2->tensorflow-transform==0.24.0) (3.5.0)\n",
      "Building wheels for collected packages: google-cloud-profiler\n",
      "  Building wheel for google-cloud-profiler (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for google-cloud-profiler: filename=google_cloud_profiler-3.0.5-cp37-cp37m-linux_x86_64.whl size=738112 sha256=41e8fffbb42f8bc16ffe4e6e9c8f76c03757b7e0639773305ada617bfc53bf74\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/9f/24/e7/54a8a406d778d2d81aafc6d45b6cc9cca479373d2037f9102a\n",
      "Successfully built google-cloud-profiler\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Installing collected packages: absl-py, google-api-python-client, gast, astunparse, tensorflow, google-cloud-profiler, google-cloud-bigtable, google-apitools, apache-beam, tensorflow-serving-api, tensorflow-metadata, tfx-bsl, tensorflow-transform\n",
      "  Attempting uninstall: absl-py\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "    Found existing installation: absl-py 0.13.0\n",
      "    Uninstalling absl-py-0.13.0:\n",
      "      Successfully uninstalled absl-py-0.13.0\n",
      "  Attempting uninstall: google-api-python-client\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "    Found existing installation: google-api-python-client 2.12.0\n",
      "    Uninstalling google-api-python-client-2.12.0:\n",
      "      Successfully uninstalled google-api-python-client-2.12.0\n",
      "  Attempting uninstall: google-cloud-bigtable\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "    Found existing installation: google-cloud-bigtable 2.3.0\n",
      "    Uninstalling google-cloud-bigtable-2.3.0:\n",
      "      Successfully uninstalled google-cloud-bigtable-2.3.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Successfully installed absl-py-0.10.0 apache-beam-2.31.0 astunparse-1.6.3 gast-0.3.3 google-api-python-client-1.12.8 google-apitools-0.5.31 google-cloud-bigtable-1.7.0 google-cloud-profiler-3.0.5 tensorflow-2.3.3 tensorflow-metadata-0.24.0 tensorflow-serving-api-2.3.0 tensorflow-transform-0.24.0 tfx-bsl-0.24.1\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow==2.3.0 apache-beam[gcp]==2.24.0\n",
    "!pip3 install tensorflow-transform==0.24.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5fe349",
   "metadata": {},
   "source": [
    "**NOTE**: You may ignore specific incompatibility errors and warnings. These components and issues do not impact your ability to complete the lab.\n",
    "Download .whl file for tensorflow-transform. We will pass this file to Beam Pipeline Options so it is installed on the DataFlow workers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a63b484d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Found existing installation: google-cloud-bigquery 2.20.0\n",
      "Uninstalling google-cloud-bigquery-2.20.0:\n",
      "  Successfully uninstalled google-cloud-bigquery-2.20.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Collecting google-cloud-bigquery\n",
      "  Downloading google_cloud_bigquery-2.21.0-py2.py3-none-any.whl (193 kB)\n",
      "\u001b[K     |████████████████████████████████| 193 kB 7.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery) (21.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery) (3.16.0)\n",
      "Requirement already satisfied: google-resumable-media<2.0dev,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery) (1.3.1)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery) (1.7.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.38.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery) (1.38.1)\n",
      "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.29.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery) (1.30.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery) (2.25.1)\n",
      "Requirement already satisfied: proto-plus>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery) (1.19.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.29.0->google-cloud-bigquery) (1.53.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.29.0->google-cloud-bigquery) (2021.1)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.29.0->google-cloud-bigquery) (49.6.0.post20210108)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.25.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.29.0->google-cloud-bigquery) (1.32.1)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.29.0->google-cloud-bigquery) (1.16.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.29.0->google-cloud-bigquery) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.29.0->google-cloud-bigquery) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.29.0->google-cloud-bigquery) (3.1.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery) (1.1.2)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery) (2.20)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->google-cloud-bigquery) (2.4.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.29.0->google-cloud-bigquery) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-bigquery) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-bigquery) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-bigquery) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-bigquery) (2021.5.30)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Installing collected packages: google-cloud-bigquery\n",
      "Successfully installed google-cloud-bigquery-2.21.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Found existing installation: pyarrow 0.17.1\n",
      "Uninstalling pyarrow-0.17.1:\n",
      "  Successfully uninstalled pyarrow-0.17.1\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-4.0.1-cp37-cp37m-manylinux2014_x86_64.whl (21.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 21.8 MB 8.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.7/site-packages (from pyarrow) (1.18.5)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Installing collected packages: pyarrow\n",
      "\u001b[33m  WARNING: The script plasma_store is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tfx-bsl 0.24.1 requires pyarrow<0.18,>=0.17, but you have pyarrow 4.0.1 which is incompatible.\u001b[0m\n",
      "Successfully installed pyarrow-4.0.1\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Found existing installation: pandas 1.3.0\n",
      "Uninstalling pandas-1.3.0:\n",
      "  Successfully uninstalled pandas-1.3.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (10.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.8 MB 7.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Installing collected packages: pandas\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tfx-bsl 0.24.1 requires pyarrow<0.18,>=0.17, but you have pyarrow 4.0.1 which is incompatible.\n",
      "phik 0.11.2 requires scipy>=1.5.2, but you have scipy 1.4.1 which is incompatible.\u001b[0m\n",
      "Successfully installed pandas-1.3.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 uninstall google-cloud-bigquery --yes\n",
    "!pip3 install --user google-cloud-bigquery\n",
    "!pip3 uninstall pyarrow --yes\n",
    "!pip3 install pyarrow --user\n",
    "!pip3 uninstall pandas --yes\n",
    "!pip3 install pandas --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31caa665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Collecting tensorflow-transform==0.24.0\n",
      "  Using cached tensorflow_transform-0.24.0-py3-none-any.whl (373 kB)\n",
      "Saved ./tensorflow_transform-0.24.0-py3-none-any.whl\n",
      "Successfully downloaded tensorflow-transform\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip download tensorflow-transform==0.24.0 --no-deps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb68047",
   "metadata": {},
   "source": [
    "<b>Restart the kernel</b> (click on the reload button above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7360408",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0708d480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apache-beam==2.31.0\n",
      "tensorflow==2.3.3\n",
      "tensorflow-estimator==2.3.0\n",
      "tensorflow-metadata==0.24.0\n",
      "tensorflow-serving-api==2.3.0\n",
      "tensorflow-transform==0.24.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Output installed packages in requirements format.\n",
    "pip freeze | grep -e 'flow\\|beam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d0facda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-19 01:37:22.861725: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
      "2021-07-19 01:37:22.861775: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.3\n"
     ]
    }
   ],
   "source": [
    "# Import data processing libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "# Python shutil module enables us to operate with file objects easily and without diving into file objects a lot.\n",
    "import shutil\n",
    "# Show the currently installed version of TensorFlow\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6898af78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change these to try this notebook out\n",
    "import os\n",
    "\n",
    "BUCKET = os.popen( \"gcloud config list --format 'value(core.project)'\" ).read()\n",
    "PROJECT = BUCKET\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64c73004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwiklabs-gcp-03-dcea475cfe91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The OS module in python provides functions for interacting with the operating system.\n",
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION\n",
    "\n",
    "print( BUCKET )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c72a944",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# gcloud config set - set a Cloud SDK property\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "357ab6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "grep: /: Is a directory\n",
      "Creating gs://qwiklabs-gcp-03-dcea475cfe91/...\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Create bucket\n",
    "if ! gsutil ls | grep -q gs://${BUCKET}/; then\n",
    "  gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8631f437",
   "metadata": {},
   "source": [
    "## Input source: BigQuery\n",
    "\n",
    "Get data from BigQuery but defer the majority of filtering etc. to Beam.\n",
    "Note that the dayofweek column is now strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fce2d4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    WITH daynames AS\n",
      "    (SELECT ['Sun', 'Mon', 'Tues', 'Wed', 'Thurs', 'Fri', 'Sat'] AS daysofweek)\n",
      "    SELECT\n",
      "    (tolls_amount + fare_amount) AS fare_amount,\n",
      "    daysofweek[ORDINAL(EXTRACT(DAYOFWEEK FROM pickup_datetime))] AS dayofweek,\n",
      "    EXTRACT(HOUR FROM pickup_datetime) AS hourofday,\n",
      "    pickup_longitude AS pickuplon,\n",
      "    pickup_latitude AS pickuplat,\n",
      "    dropoff_longitude AS dropofflon,\n",
      "    dropoff_latitude AS dropofflat,\n",
      "    passenger_count AS passengers,\n",
      "    'notneeded' AS key\n",
      "    FROM\n",
      "    `nyc-tlc.yellow.trips`, daynames\n",
      "    WHERE\n",
      "    trip_distance > 0 AND fare_amount > 0\n",
      "     AND ABS(MOD(FARM_FINGERPRINT(CAST(\n",
      "        pickup_datetime AS STRING)), 100000)) = 2\n"
     ]
    }
   ],
   "source": [
    "# Import Google BigQuery API client library\n",
    "from google.cloud import bigquery\n",
    "\n",
    "\n",
    "def create_query(phase, EVERY_N):\n",
    "    \"\"\"Creates a query with the proper splits.\n",
    "\n",
    "    Args:\n",
    "        phase: int, 1=train, 2=valid.\n",
    "        EVERY_N: int, take an example EVERY_N rows.\n",
    "\n",
    "    Returns:\n",
    "        Query string with the proper splits.\n",
    "    \"\"\"\n",
    "    base_query = \"\"\"\n",
    "    WITH daynames AS\n",
    "    (SELECT ['Sun', 'Mon', 'Tues', 'Wed', 'Thurs', 'Fri', 'Sat'] AS daysofweek)\n",
    "    SELECT\n",
    "    (tolls_amount + fare_amount) AS fare_amount,\n",
    "    daysofweek[ORDINAL(EXTRACT(DAYOFWEEK FROM pickup_datetime))] AS dayofweek,\n",
    "    EXTRACT(HOUR FROM pickup_datetime) AS hourofday,\n",
    "    pickup_longitude AS pickuplon,\n",
    "    pickup_latitude AS pickuplat,\n",
    "    dropoff_longitude AS dropofflon,\n",
    "    dropoff_latitude AS dropofflat,\n",
    "    passenger_count AS passengers,\n",
    "    'notneeded' AS key\n",
    "    FROM\n",
    "    `nyc-tlc.yellow.trips`, daynames\n",
    "    WHERE\n",
    "    trip_distance > 0 AND fare_amount > 0\n",
    "    \"\"\"\n",
    "    if EVERY_N is None:\n",
    "        if phase < 2:\n",
    "            # training\n",
    "            query = \"\"\"{0} AND ABS(MOD(FARM_FINGERPRINT(CAST\n",
    "            (pickup_datetime AS STRING), 4)) < 2\"\"\".format(base_query)\n",
    "        else:\n",
    "            query = \"\"\"{0} AND ABS(MOD(FARM_FINGERPRINT(CAST(\n",
    "            pickup_datetime AS STRING), 4)) = {1}\"\"\".format(base_query, phase)\n",
    "    else:\n",
    "        query = \"\"\"{0} AND ABS(MOD(FARM_FINGERPRINT(CAST(\n",
    "        pickup_datetime AS STRING)), {1})) = {2}\"\"\".format(\n",
    "            base_query, EVERY_N, phase)\n",
    "\n",
    "    return query\n",
    "\n",
    "query = create_query(2, 100000)\n",
    "\n",
    "print( query )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2943f996",
   "metadata": {},
   "source": [
    "Let's pull this query down into a Pandas DataFrame and take a look at some of the statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab387fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.01s: 100%|██████████| 3/3 [00:00<00:00, 1194.62query/s]                        \n",
      "Downloading: 100%|██████████| 11181/11181 [00:01<00:00, 7949.42rows/s]\n"
     ]
    }
   ],
   "source": [
    "%%bigquery df_valid\n",
    "\n",
    "WITH daynames AS\n",
    "(SELECT ['Sun', 'Mon', 'Tues', 'Wed', 'Thurs', 'Fri', 'Sat'] AS daysofweek)\n",
    "SELECT\n",
    "(tolls_amount + fare_amount) AS fare_amount,\n",
    "daysofweek[ORDINAL(EXTRACT(DAYOFWEEK FROM pickup_datetime))] AS dayofweek,\n",
    "EXTRACT(HOUR FROM pickup_datetime) AS hourofday,\n",
    "pickup_longitude AS pickuplon,\n",
    "pickup_latitude AS pickuplat,\n",
    "dropoff_longitude AS dropofflon,\n",
    "dropoff_latitude AS dropofflat,\n",
    "passenger_count AS passengers,\n",
    "'notneeded' AS key\n",
    "FROM\n",
    "`nyc-tlc.yellow.trips`, daynames\n",
    "WHERE\n",
    "trip_distance > 0 AND fare_amount > 0\n",
    " AND ABS(MOD(FARM_FINGERPRINT(CAST(\n",
    "    pickup_datetime AS STRING)), 100000)) = 2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b99290ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hourofday</th>\n",
       "      <th>pickuplon</th>\n",
       "      <th>pickuplat</th>\n",
       "      <th>dropofflon</th>\n",
       "      <th>dropofflat</th>\n",
       "      <th>passengers</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.5</td>\n",
       "      <td>Thurs</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.984795</td>\n",
       "      <td>40.726577</td>\n",
       "      <td>-74.006751</td>\n",
       "      <td>40.734390</td>\n",
       "      <td>1</td>\n",
       "      <td>notneeded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Sun</td>\n",
       "      <td>0</td>\n",
       "      <td>-74.002333</td>\n",
       "      <td>40.739887</td>\n",
       "      <td>-73.978842</td>\n",
       "      <td>40.741165</td>\n",
       "      <td>3</td>\n",
       "      <td>notneeded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Sun</td>\n",
       "      <td>0</td>\n",
       "      <td>-74.000664</td>\n",
       "      <td>40.728981</td>\n",
       "      <td>-73.979706</td>\n",
       "      <td>40.727139</td>\n",
       "      <td>3</td>\n",
       "      <td>notneeded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>Sun</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.985742</td>\n",
       "      <td>40.722115</td>\n",
       "      <td>-73.993937</td>\n",
       "      <td>40.741187</td>\n",
       "      <td>1</td>\n",
       "      <td>notneeded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.5</td>\n",
       "      <td>Mon</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.994442</td>\n",
       "      <td>40.750685</td>\n",
       "      <td>-73.981005</td>\n",
       "      <td>40.720737</td>\n",
       "      <td>2</td>\n",
       "      <td>notneeded</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fare_amount dayofweek  hourofday  pickuplon  pickuplat  dropofflon  \\\n",
       "0          8.5     Thurs          0 -73.984795  40.726577  -74.006751   \n",
       "1          9.0       Sun          0 -74.002333  40.739887  -73.978842   \n",
       "2          9.0       Sun          0 -74.000664  40.728981  -73.979706   \n",
       "3         15.0       Sun          0 -73.985742  40.722115  -73.993937   \n",
       "4         13.5       Mon          0 -73.994442  40.750685  -73.981005   \n",
       "\n",
       "   dropofflat  passengers        key  \n",
       "0   40.734390           1  notneeded  \n",
       "1   40.741165           3  notneeded  \n",
       "2   40.727139           3  notneeded  \n",
       "3   40.741187           1  notneeded  \n",
       "4   40.720737           2  notneeded  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>hourofday</th>\n",
       "      <th>pickuplon</th>\n",
       "      <th>pickuplat</th>\n",
       "      <th>dropofflon</th>\n",
       "      <th>dropofflat</th>\n",
       "      <th>passengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11181.000000</td>\n",
       "      <td>11181.000000</td>\n",
       "      <td>11181.000000</td>\n",
       "      <td>11181.000000</td>\n",
       "      <td>11181.000000</td>\n",
       "      <td>11181.000000</td>\n",
       "      <td>11181.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.242599</td>\n",
       "      <td>13.244075</td>\n",
       "      <td>-72.576852</td>\n",
       "      <td>39.973146</td>\n",
       "      <td>-72.748974</td>\n",
       "      <td>40.006091</td>\n",
       "      <td>1.722118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.447462</td>\n",
       "      <td>6.548354</td>\n",
       "      <td>10.133452</td>\n",
       "      <td>5.777329</td>\n",
       "      <td>12.981577</td>\n",
       "      <td>5.664887</td>\n",
       "      <td>1.351062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-78.133333</td>\n",
       "      <td>-73.991278</td>\n",
       "      <td>-751.400000</td>\n",
       "      <td>-73.977970</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>-73.991849</td>\n",
       "      <td>40.734954</td>\n",
       "      <td>-73.991236</td>\n",
       "      <td>40.734008</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.500000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>-73.981824</td>\n",
       "      <td>40.752640</td>\n",
       "      <td>-73.980164</td>\n",
       "      <td>40.753427</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.500000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>-73.967418</td>\n",
       "      <td>40.766700</td>\n",
       "      <td>-73.964153</td>\n",
       "      <td>40.767832</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>143.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>40.806487</td>\n",
       "      <td>41.366138</td>\n",
       "      <td>40.785400</td>\n",
       "      <td>41.366138</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fare_amount     hourofday     pickuplon     pickuplat    dropofflon  \\\n",
       "count  11181.000000  11181.000000  11181.000000  11181.000000  11181.000000   \n",
       "mean      11.242599     13.244075    -72.576852     39.973146    -72.748974   \n",
       "std        9.447462      6.548354     10.133452      5.777329     12.981577   \n",
       "min        2.500000      0.000000    -78.133333    -73.991278   -751.400000   \n",
       "25%        6.000000      9.000000    -73.991849     40.734954    -73.991236   \n",
       "50%        8.500000     14.000000    -73.981824     40.752640    -73.980164   \n",
       "75%       12.500000     19.000000    -73.967418     40.766700    -73.964153   \n",
       "max      143.000000     23.000000     40.806487     41.366138     40.785400   \n",
       "\n",
       "         dropofflat    passengers  \n",
       "count  11181.000000  11181.000000  \n",
       "mean      40.006091      1.722118  \n",
       "std        5.664887      1.351062  \n",
       "min      -73.977970      0.000000  \n",
       "25%       40.734008      1.000000  \n",
       "50%       40.753427      1.000000  \n",
       "75%       40.767832      2.000000  \n",
       "max       41.366138      6.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `head()` function is used to get the first n rows of dataframe\n",
    "display(df_valid.head())\n",
    "# `describe()` is use to get the statistical summary of the DataFrame\n",
    "df_valid.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a779058a",
   "metadata": {},
   "source": [
    "## Create ML dataset using tf.transform and Dataflow\n",
    "\n",
    "Let's use Cloud Dataflow to read in the BigQuery data and write it out as TFRecord files. Along the way, let's use tf.transform to do scaling and transforming. Using tf.transform allows us to save the metadata to ensure that the appropriate transformations get carried out during prediction as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77f3868",
   "metadata": {},
   "source": [
    "`transformed_data` is type `pcollection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d13756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a module named `datetime` to work with dates as date objects.\n",
    "import datetime\n",
    "# Import data processing libraries and modules\n",
    "import tensorflow as tf\n",
    "import apache_beam as beam\n",
    "import tensorflow_transform as tft\n",
    "import tensorflow_metadata as tfmd\n",
    "from tensorflow_transform.beam import impl as beam_impl\n",
    "\n",
    "\n",
    "def is_valid(inputs):\n",
    "    \"\"\"Check to make sure the inputs are valid.\n",
    "\n",
    "    Args:\n",
    "        inputs: dict, dictionary of TableRow data from BigQuery.\n",
    "\n",
    "    Returns:\n",
    "        True if the inputs are valid and False if they are not.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pickup_longitude = inputs['pickuplon']\n",
    "        dropoff_longitude = inputs['dropofflon']\n",
    "        pickup_latitude = inputs['pickuplat']\n",
    "        dropoff_latitude = inputs['dropofflat']\n",
    "        hourofday = inputs['hourofday']\n",
    "        dayofweek = inputs['dayofweek']\n",
    "        passenger_count = inputs['passengers']\n",
    "        fare_amount = inputs['fare_amount']\n",
    "        return fare_amount >= 2.5 and pickup_longitude > -78 \\\n",
    "            and pickup_longitude < -70 and dropoff_longitude > -78 \\\n",
    "            and dropoff_longitude < -70 and pickup_latitude > 37 \\\n",
    "            and pickup_latitude < 45 and dropoff_latitude > 37 \\\n",
    "            and dropoff_latitude < 45 and passenger_count > 0\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "def preprocess_tft(inputs):\n",
    "    \"\"\"Preprocess the features and add engineered features with tf transform.\n",
    "\n",
    "    Args:\n",
    "        dict, dictionary of TableRow data from BigQuery.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of preprocessed data after scaling and feature engineering.\n",
    "    \"\"\"\n",
    "    import datetime\n",
    "    print(inputs)\n",
    "    result = {}\n",
    "    result['fare_amount'] = tf.identity(inputs['fare_amount'])\n",
    "    # build a vocabulary\n",
    "    # TODO 1\n",
    "    result['dayofweek'] = tft.string_to_int(inputs['dayofweek'])\n",
    "    result['hourofday'] = tf.identity(inputs['hourofday'])  # pass through\n",
    "    # scaling numeric values\n",
    "    # TODO 2\n",
    "    result['pickuplon'] = (tft.scale_to_0_1(inputs['pickuplon']))\n",
    "    result['pickuplat'] = (tft.scale_to_0_1(inputs['pickuplat']))\n",
    "    result['dropofflon'] = (tft.scale_to_0_1(inputs['dropofflon']))\n",
    "    result['dropofflat'] = (tft.scale_to_0_1(inputs['dropofflat']))\n",
    "    result['passengers'] = tf.cast(inputs['passengers'], tf.float32)  # a cast\n",
    "    # arbitrary TF func\n",
    "    result['key'] = tf.as_string(tf.ones_like(inputs['passengers']))\n",
    "    # engineered features\n",
    "    latdiff = inputs['pickuplat'] - inputs['dropofflat']\n",
    "    londiff = inputs['pickuplon'] - inputs['dropofflon']\n",
    "    # Scale our engineered features latdiff and londiff between 0 and 1\n",
    "    # TODO 3\n",
    "    result['latdiff'] = tft.scale_to_0_1(latdiff)\n",
    "    result['londiff'] = tft.scale_to_0_1(londiff)\n",
    "    dist = tf.sqrt(latdiff * latdiff + londiff * londiff)\n",
    "    result['euclidean'] = tft.scale_to_0_1(dist)\n",
    "    return result\n",
    "\n",
    "\n",
    "def preprocess(in_test_mode):\n",
    "    \"\"\"Sets up preprocess pipeline.\n",
    "\n",
    "    Args:\n",
    "        in_test_mode: bool, False to launch DataFlow job, True to run locally.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import os.path\n",
    "    import tempfile\n",
    "    from apache_beam.io import tfrecordio\n",
    "    from tensorflow_transform.coders import example_proto_coder\n",
    "    from tensorflow_transform.tf_metadata import dataset_metadata\n",
    "    from tensorflow_transform.tf_metadata import dataset_schema\n",
    "    from tensorflow_transform.beam import tft_beam_io\n",
    "    from tensorflow_transform.beam.tft_beam_io import transform_fn_io\n",
    "\n",
    "    job_name = 'preprocess-taxi-features' + '-'\n",
    "    job_name += datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "    if in_test_mode:\n",
    "        import shutil\n",
    "        print('Launching local job ... hang on')\n",
    "        OUTPUT_DIR = './preproc_tft'\n",
    "        shutil.rmtree(OUTPUT_DIR, ignore_errors=True)\n",
    "        EVERY_N = 100000\n",
    "    else:\n",
    "        print('Launching Dataflow job {} ... hang on'.format(job_name))\n",
    "        OUTPUT_DIR = 'gs://{0}/taxifare/preproc_tft/'.format(BUCKET)\n",
    "        import subprocess\n",
    "        subprocess.call('gsutil rm -r {}'.format(OUTPUT_DIR).split())\n",
    "        EVERY_N = 10000\n",
    "\n",
    "    options = {\n",
    "        'staging_location': os.path.join(OUTPUT_DIR, 'tmp', 'staging'),\n",
    "        'temp_location': os.path.join(OUTPUT_DIR, 'tmp'),\n",
    "        'job_name': job_name,\n",
    "        'project': PROJECT,\n",
    "        'num_workers': 1,\n",
    "        'max_num_workers': 1,\n",
    "        'teardown_policy': 'TEARDOWN_ALWAYS',\n",
    "        'no_save_main_session': True,\n",
    "        'direct_num_workers': 1,\n",
    "        'extra_packages': ['tensorflow_transform-0.24.0-py3-none-any.whl']\n",
    "        }\n",
    "\n",
    "    opts = beam.pipeline.PipelineOptions(flags=[], **options)\n",
    "    if in_test_mode:\n",
    "        RUNNER = 'DirectRunner'\n",
    "    else:\n",
    "        RUNNER = 'DataflowRunner'\n",
    "\n",
    "    # Set up raw data metadata\n",
    "    raw_data_schema = {\n",
    "        colname: dataset_schema.ColumnSchema(\n",
    "            tf.string, [], dataset_schema.FixedColumnRepresentation())\n",
    "        for colname in 'dayofweek,key'.split(',')\n",
    "    }\n",
    "\n",
    "    raw_data_schema.update({\n",
    "        colname: dataset_schema.ColumnSchema(\n",
    "            tf.float32, [], dataset_schema.FixedColumnRepresentation())\n",
    "        for colname in\n",
    "        'fare_amount,pickuplon,pickuplat,dropofflon,dropofflat'.split(',')\n",
    "    })\n",
    "\n",
    "    raw_data_schema.update({\n",
    "        colname: dataset_schema.ColumnSchema(\n",
    "            tf.int64, [], dataset_schema.FixedColumnRepresentation())\n",
    "        for colname in 'hourofday,passengers'.split(',')\n",
    "    })\n",
    "\n",
    "    raw_data_metadata = dataset_metadata.DatasetMetadata(\n",
    "        dataset_schema.Schema(raw_data_schema))\n",
    "\n",
    "    # Run Beam\n",
    "    with beam.Pipeline(RUNNER, options=opts) as p:\n",
    "        with beam_impl.Context(temp_dir=os.path.join(OUTPUT_DIR, 'tmp')):\n",
    "            # Save the raw data metadata\n",
    "            (raw_data_metadata |\n",
    "                'WriteInputMetadata' >> tft_beam_io.WriteMetadata(\n",
    "                    os.path.join(\n",
    "                        OUTPUT_DIR, 'metadata/rawdata_metadata'), pipeline=p))\n",
    "\n",
    "            # Read training data from bigquery and filter rows\n",
    "            raw_data = (p | 'train_read' >> beam.io.Read(\n",
    "                    beam.io.BigQuerySource(\n",
    "                        query=create_query(1, EVERY_N),\n",
    "                        use_standard_sql=True)) |\n",
    "                        'train_filter' >> beam.Filter(is_valid))\n",
    "\n",
    "            raw_dataset = (raw_data, raw_data_metadata)\n",
    "\n",
    "            # Analyze and transform training data\n",
    "            # TODO 4\n",
    "            transformed_dataset, transform_fn = (\n",
    "                raw_dataset | beam_impl.AnalyzeAndTransformDataset(\n",
    "                    preprocess_tft))\n",
    "            transformed_data, transformed_metadata = transformed_dataset\n",
    "\n",
    "            # Save transformed train data to disk in efficient tfrecord format\n",
    "            transformed_data | 'WriteTrainData' >> tfrecordio.WriteToTFRecord(\n",
    "                os.path.join(OUTPUT_DIR, 'train'), file_name_suffix='.gz',\n",
    "                coder=example_proto_coder.ExampleProtoCoder(\n",
    "                    transformed_metadata.schema))\n",
    "\n",
    "            # Read eval data from bigquery and filter rows\n",
    "            # TODO 5\n",
    "            raw_test_data = (p | 'eval_read' >> beam.io.Read(\n",
    "                beam.io.BigQuerySource(\n",
    "                    query=create_query(2, EVERY_N),\n",
    "                    use_standard_sql=True)) | 'eval_filter' >> beam.Filter(\n",
    "                        is_valid))\n",
    "\n",
    "            raw_test_dataset = (raw_test_data, raw_data_metadata)\n",
    "\n",
    "            # Transform eval data\n",
    "            transformed_test_dataset = (\n",
    "                (raw_test_dataset, transform_fn) | beam_impl.TransformDataset()\n",
    "                )\n",
    "            transformed_test_data, _ = transformed_test_dataset\n",
    "\n",
    "            # Save transformed train data to disk in efficient tfrecord format\n",
    "            (transformed_test_data |\n",
    "                'WriteTestData' >> tfrecordio.WriteToTFRecord(\n",
    "                    os.path.join(OUTPUT_DIR, 'eval'), file_name_suffix='.gz',\n",
    "                    coder=example_proto_coder.ExampleProtoCoder(\n",
    "                        transformed_metadata.schema)))\n",
    "\n",
    "            # Save transformation function to disk for use at serving time\n",
    "            (transform_fn |\n",
    "                'WriteTransformFn' >> transform_fn_io.WriteTransformFn(\n",
    "                    os.path.join(OUTPUT_DIR, 'metadata')))\n",
    "\n",
    "# Change to True to run locally\n",
    "preprocess(in_test_mode=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea17378",
   "metadata": {},
   "source": [
    "This will take __10-15 minutes__. You cannot go on in this lab until your DataFlow job has successfully completed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fb68ef",
   "metadata": {},
   "source": [
    "**Note**: The above command may fail with an error **`Workflow failed. Causes: There was a problem refreshing your credentials`**. In that case, `re-run` the command again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212cc7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# ls preproc_tft\n",
    "# `ls` command show the full list or content of your directory\n",
    "gsutil ls gs://${BUCKET}/taxifare/preproc_tft/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf26965",
   "metadata": {},
   "source": [
    "## Train off preprocessed data ##\n",
    "Now that we have our data ready and verified it is in the correct location we can train our taxifare model locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd88727",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Train our taxifare model locally\n",
    "rm -r ./taxi_trained\n",
    "export PYTHONPATH=${PYTHONPATH}:$PWD\n",
    "python3 -m tft_trainer.task \\\n",
    "    --train_data_path=\"gs://${BUCKET}/taxifare/preproc_tft/train*\" \\\n",
    "    --eval_data_path=\"gs://${BUCKET}/taxifare/preproc_tft/eval*\"  \\\n",
    "    --output_dir=./taxi_trained \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1597106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `ls` command show the full list or content of your directory\n",
    "!ls $PWD/taxi_trained/export/exporter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01866d03",
   "metadata": {},
   "source": [
    "Now let's create fake data in JSON format and use it to serve a prediction with gcloud ai-platform local predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a507b016",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /tmp/test.json\n",
    "{\"dayofweek\":0, \"hourofday\":17, \"pickuplon\": -73.885262, \"pickuplat\": 40.773008, \"dropofflon\": -73.987232, \"dropofflat\": 40.732403, \"passengers\": 2.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a18233",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo find \"/usr/lib/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine\" -name '*.pyc' -delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f63898a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Serve a prediction with gcloud ai-platform local predict\n",
    "model_dir=$(ls $PWD/taxi_trained/export/exporter/)\n",
    "gcloud ai-platform local predict \\\n",
    "    --model-dir=./taxi_trained/export/exporter/${model_dir} \\\n",
    "    --json-instances=/tmp/test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a5742a",
   "metadata": {},
   "source": [
    "Copyright 2021 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m75"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
